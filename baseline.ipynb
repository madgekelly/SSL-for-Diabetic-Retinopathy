{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d19b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SSL_for_Diabetic_Retinopathy.data import data_loader\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60d1047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "0.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd44aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c52807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec96d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "image_path = '/home/mkelly_mehresearch_org/data/kaggle-eyepacs-data/images/'\n",
    "csv_path = '/home/mkelly_mehresearch_org/data/kaggle-eyepacs-data/clean_binary.csv'\n",
    "csv_path2 = '/home/mkelly_mehresearch_org/data/kaggle-eyepacs-data/clean_binary.csv'\n",
    "test_csv = 'subset.csv'\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.ToTensor()\n",
    "                               ])\n",
    "train_data = data_loader.DataSetFromFolder(image_path, csv_path, transform, mode='train', index=False)\n",
    "val_data = data_loader.DataSetFromFolder(image_path, csv_path2, transform, mode='validation', index=False)\n",
    "sampler = ImbalancedDatasetSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=64, sampler=sampler, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7ef2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, criterion, optimiser, num_epochs,\n",
    "          device, scheduler=None, start_point=0, save_dir=None, \n",
    "          val_data=None):\n",
    "    # create the directory to store the model and training history\n",
    "    try:\n",
    "        os.mkdir(save_dir)\n",
    "    except:\n",
    "        print('Directory already exists!!')\n",
    "\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    val_accuracies = None\n",
    "    num_batchs = len(train_data)\n",
    "    for epoch in range(start_point, num_epochs):\n",
    "\n",
    "        print('epoch {} of {}'.format(epoch, num_epochs))\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        data_size = 0\n",
    "        for batch_no, (images, labels) in enumerate(train_data):\n",
    "            batch_size = len(images)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            corrects = (preds.data == labels.data).sum().item()\n",
    "            running_corrects += corrects\n",
    "            data_size += batch_size\n",
    "\n",
    "        # at each epoch if validation data is available\n",
    "        # calculate validation accuracy\n",
    "        val_acc = None\n",
    "        if val_data is not None:\n",
    "            val_accuracies = []\n",
    "            # model.eval()\n",
    "            with torch.no_grad():\n",
    "                running_val_corrects = 0\n",
    "                val_size = 0\n",
    "                for images, labels in val_data:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    running_val_corrects += (preds.data == labels.data).sum().item()\n",
    "                    val_size += len(images)\n",
    "            val_acc = running_val_corrects / val_size\n",
    "            val_accuracies.append(val_acc)\n",
    "            # model.train()\n",
    "\n",
    "        total_loss = running_loss / data_size\n",
    "        losses.append(total_loss)\n",
    "        total_acc = running_corrects / data_size\n",
    "        accuracies.append(total_acc)\n",
    "\n",
    "        # save the history if given save_path\n",
    "        if save_dir is not None:\n",
    "            with open('{}/history.csv'.format(save_dir), 'a+', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow([total_loss, total_acc, val_acc])\n",
    "\n",
    "        print('epoch loss: {} epoch accuracy: {} validation accuracy: {}'.format(total_loss, total_acc, val_acc))\n",
    "\n",
    "        # save the model every 5 epochs if give save_path\n",
    "        # we are note decaying the learning rate\n",
    "        # so we don't need to save the optimsier\n",
    "        \n",
    "        if save_dir is not None:\n",
    "            if (epoch % 5 == 0) | (epoch == num_epochs - 1):\n",
    "                model.state_dict(torch.save(model.state_dict(), save_dir + 'epoch_{}'.format(epoch)))\n",
    "                \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    return model, losses, accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdc649a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "fine_tune = False\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n",
    "r18 = models.resnet18(pretrained=False) \n",
    "\n",
    "if not fine_tune:\n",
    "    for param in r18.parameters():\n",
    "        param.requires_grad = False\n",
    "    r18.eval()\n",
    "    \n",
    "features = r18.fc.in_features\n",
    "r18.fc = torch.nn.Linear(features, 2)\n",
    "\n",
    "r18 = r18.to(dev)\n",
    "\n",
    "trainable_params = r18.parameters()\n",
    "if not fine_tune:\n",
    "    trainable_params = []\n",
    "    for name, param in r18.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            trainable_params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0684cdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 1.1733875692197167 epoch accuracy: 0.5120501285347043 validation accuracy: 0.7889204545454546\n",
      "epoch 1 of 25\n",
      "epoch loss: 1.1175226720868776 epoch accuracy: 0.5345035347043702 validation accuracy: 0.7417613636363637\n",
      "epoch 2 of 25\n",
      "epoch loss: 3.567212635110154 epoch accuracy: 0.5096200192802056 validation accuracy: 0.23650568181818182\n",
      "epoch 3 of 25\n",
      "epoch loss: 10.31633847691406 epoch accuracy: 0.5091380141388174 validation accuracy: 0.4971590909090909\n",
      "epoch 4 of 25\n",
      "epoch loss: 15.492928085106504 epoch accuracy: 0.5148417416452442 validation accuracy: 0.6362215909090909\n",
      "epoch 5 of 25\n",
      "epoch loss: 21.394456627129895 epoch accuracy: 0.514480237789203 validation accuracy: 0.8079545454545455\n",
      "epoch 6 of 25\n",
      "epoch loss: 21.56015670728561 epoch accuracy: 0.5152032455012854 validation accuracy: 0.8164772727272728\n",
      "epoch 7 of 25\n",
      "epoch loss: 31.170816846862245 epoch accuracy: 0.5124718830334191 validation accuracy: 0.5066761363636364\n",
      "epoch 8 of 25\n",
      "epoch loss: 49.274399409257356 epoch accuracy: 0.5065874035989717 validation accuracy: 0.184375\n",
      "epoch 9 of 25\n",
      "epoch loss: 46.745514885625376 epoch accuracy: 0.515745501285347 validation accuracy: 0.8134943181818182\n",
      "epoch 10 of 25\n",
      "epoch loss: 45.938794600626494 epoch accuracy: 0.5194207904884319 validation accuracy: 0.19943181818181818\n",
      "epoch 11 of 25\n",
      "epoch loss: 35.868294113399436 epoch accuracy: 0.5326759318766067 validation accuracy: 0.8122159090909091\n",
      "epoch 12 of 25\n",
      "epoch loss: 41.47441807381598 epoch accuracy: 0.518517030848329 validation accuracy: 0.8125\n",
      "epoch 13 of 25\n",
      "epoch loss: 36.46991730042779 epoch accuracy: 0.5240600899742931 validation accuracy: 0.3471590909090909\n",
      "epoch 14 of 25\n",
      "epoch loss: 32.29633593007654 epoch accuracy: 0.5388616645244216 validation accuracy: 0.2409090909090909\n",
      "epoch 15 of 25\n",
      "epoch loss: 28.133763929259196 epoch accuracy: 0.5382993251928021 validation accuracy: 0.8159090909090909\n",
      "epoch 16 of 25\n",
      "epoch loss: 24.4530773260906 epoch accuracy: 0.5333587724935732 validation accuracy: 0.40397727272727274\n",
      "epoch 17 of 25\n",
      "epoch loss: 20.727785690278196 epoch accuracy: 0.545730237789203 validation accuracy: 0.6411931818181819\n",
      "epoch 18 of 25\n",
      "epoch loss: 21.50465743707201 epoch accuracy: 0.5388616645244216 validation accuracy: 0.5795454545454546\n",
      "epoch 19 of 25\n",
      "epoch loss: 19.941802964418898 epoch accuracy: 0.5277554627249358 validation accuracy: 0.8021306818181818\n",
      "epoch 20 of 25\n",
      "epoch loss: 18.403403384520033 epoch accuracy: 0.5357687982005142 validation accuracy: 0.8063920454545455\n",
      "epoch 21 of 25\n",
      "epoch loss: 18.930798059257565 epoch accuracy: 0.5441838046272494 validation accuracy: 0.27372159090909093\n",
      "epoch 22 of 25\n",
      "epoch loss: 15.51301664129321 epoch accuracy: 0.5324951799485861 validation accuracy: 0.6894886363636363\n",
      "epoch 23 of 25\n",
      "epoch loss: 13.095713083419211 epoch accuracy: 0.5363713046272494 validation accuracy: 0.4744318181818182\n",
      "epoch 24 of 25\n",
      "epoch loss: 11.080655523927781 epoch accuracy: 0.5560531812339332 validation accuracy: 0.6670454545454545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ResNet(\n",
       "   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       " ),\n",
       " [1.1733875692197167,\n",
       "  1.1175226720868776,\n",
       "  3.567212635110154,\n",
       "  10.31633847691406,\n",
       "  15.492928085106504,\n",
       "  21.394456627129895,\n",
       "  21.56015670728561,\n",
       "  31.170816846862245,\n",
       "  49.274399409257356,\n",
       "  46.745514885625376,\n",
       "  45.938794600626494,\n",
       "  35.868294113399436,\n",
       "  41.47441807381598,\n",
       "  36.46991730042779,\n",
       "  32.29633593007654,\n",
       "  28.133763929259196,\n",
       "  24.4530773260906,\n",
       "  20.727785690278196,\n",
       "  21.50465743707201,\n",
       "  19.941802964418898,\n",
       "  18.403403384520033,\n",
       "  18.930798059257565,\n",
       "  15.51301664129321,\n",
       "  13.095713083419211,\n",
       "  11.080655523927781],\n",
       " [0.5120501285347043,\n",
       "  0.5345035347043702,\n",
       "  0.5096200192802056,\n",
       "  0.5091380141388174,\n",
       "  0.5148417416452442,\n",
       "  0.514480237789203,\n",
       "  0.5152032455012854,\n",
       "  0.5124718830334191,\n",
       "  0.5065874035989717,\n",
       "  0.515745501285347,\n",
       "  0.5194207904884319,\n",
       "  0.5326759318766067,\n",
       "  0.518517030848329,\n",
       "  0.5240600899742931,\n",
       "  0.5388616645244216,\n",
       "  0.5382993251928021,\n",
       "  0.5333587724935732,\n",
       "  0.545730237789203,\n",
       "  0.5388616645244216,\n",
       "  0.5277554627249358,\n",
       "  0.5357687982005142,\n",
       "  0.5441838046272494,\n",
       "  0.5324951799485861,\n",
       "  0.5363713046272494,\n",
       "  0.5560531812339332],\n",
       " [0.6670454545454545])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seeds(0)\n",
    "optimiser = optim.SGD(trainable_params, lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(dev)\n",
    "train(r18, train_loader, criterion, optimiser, num_epochs dev, scheduler=None, start_point=0, val_data=val_loader, save_dir='random_baseline_classifier/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd490311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14fec12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
