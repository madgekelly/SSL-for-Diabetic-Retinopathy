{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94429591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from SSL_for_Diabetic_Retinopathy.data import data_loader\n",
    "from SSL_for_Diabetic_Retinopathy.models import simCLR_encoders\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c04374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n",
      "0.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a44015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0edfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad6ec4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "image_path = '/home/mkelly_mehresearch_org/data/kaggle-eyepacs-data/images/'\n",
    "csv_path = '/home/mkelly_mehresearch_org/data/kaggle-eyepacs-data/clean_binary.csv'\n",
    "csv_path2 = '/home/mkelly_mehresearch_org/data/kaggle-eyepacs-data/clean_binary.csv'\n",
    "test_csv = 'subset.csv'\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomVerticalFlip(),\n",
    "                                transforms.ToTensor()\n",
    "                               ])\n",
    "train_data = data_loader.DataSetFromFolder(image_path, csv_path, transform, mode='train', index=False)\n",
    "val_data = data_loader.DataSetFromFolder(image_path, csv_path2, transform, mode='validation', index=False)\n",
    "# sampler = ImbalancedDatasetSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85736bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, criterion, optimiser, num_epochs,\n",
    "          device, scheduler=None, start_point=0, save_dir=None, \n",
    "          val_data=None):\n",
    "    # create the directory to store the model and training history\n",
    "    try:\n",
    "        os.mkdir(save_dir)\n",
    "    except:\n",
    "        print('Directory already exists!!')\n",
    "\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    val_accuracies = None\n",
    "    num_batchs = len(train_data)\n",
    "    for epoch in range(start_point, num_epochs):\n",
    "\n",
    "        print('epoch {} of {}'.format(epoch, num_epochs))\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        data_size = 0\n",
    "        for batch_no, (images, labels) in enumerate(train_data):\n",
    "            batch_size = len(images)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            corrects = (preds.data == labels.data).sum().item()\n",
    "            running_corrects += corrects\n",
    "            data_size += batch_size\n",
    "\n",
    "        # at each epoch if validation data is available\n",
    "        # calculate validation accuracy\n",
    "        val_acc = None\n",
    "        if val_data is not None:\n",
    "            val_accuracies = []\n",
    "            # model.eval()\n",
    "            with torch.no_grad():\n",
    "                running_val_corrects = 0\n",
    "                val_size = 0\n",
    "                for images, labels in val_data:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    running_val_corrects += (preds.data == labels.data).sum().item()\n",
    "                    val_size += len(images)\n",
    "            val_acc = running_val_corrects / val_size\n",
    "            val_accuracies.append(val_acc)\n",
    "            # model.train()\n",
    "\n",
    "        total_loss = running_loss / data_size\n",
    "        losses.append(total_loss)\n",
    "        total_acc = running_corrects / data_size\n",
    "        accuracies.append(total_acc)\n",
    "\n",
    "        # save the history if given save_path\n",
    "        if save_dir is not None:\n",
    "            with open('{}/history.csv'.format(save_dir), 'a+', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow([total_loss, total_acc, val_acc])\n",
    "\n",
    "        print('epoch loss: {} epoch accuracy: {} validation accuracy: {}'.format(total_loss, total_acc, val_acc))\n",
    "\n",
    "        # save the model every 5 epochs if give save_path\n",
    "        # we are note decaying the learning rate\n",
    "        # so we don't need to save the optimsier\n",
    "        \n",
    "        if save_dir is not None:\n",
    "            if (epoch % 5 == 0) | (epoch == num_epochs - 1):\n",
    "                model.state_dict(torch.save(model.state_dict(), save_dir + 'epoch_{}'.format(epoch)))\n",
    "                \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    return model, losses, accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d79b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representation_model(model):\n",
    "    removed = list(model.children())[:-1]\n",
    "    model = torch.nn.Sequential(*removed)\n",
    "    # for param in model.parameters():\n",
    "        # param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244b7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd470c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLREncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet18 encoder adapted for MNIST\n",
    "    Args:\n",
    "        forward:\n",
    "            x (Tensor): batch of images\n",
    "    Returns:\n",
    "        model(x) (Tensor): batch of encoded images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_type, out_dim, device, DDP=True, local_rank=None, checkpoint=None):\n",
    "        super(SimCLREncoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.model_dict = {'resnet18': models.resnet18(),\n",
    "                           'resnet50': models.resnet50(),\n",
    "                           'resnet101': models.resnet101()}\n",
    "        self.encoder = self.model_dict[encoder_type]\n",
    "        self.out_dim = out_dim\n",
    "        self.checkpoint = checkpoint\n",
    "        self.in_size = self._get_output_shape()\n",
    "        self.projection_head = self._get_projection_head(self.in_size)\n",
    "        self.model = self._get_model().cuda()\n",
    "        if DDP:\n",
    "            # convert all batchnorm layers to sync batch norm!\n",
    "            self.model = nn.SyncBatchNorm.convert_sync_batchnorm(self.model)\n",
    "            self.model = DistributedDataParallel(self.model, device_ids=[local_rank], output_device=local_rank)\n",
    "\n",
    "    def _get_output_shape(self, image_dim=(1, 3, 224, 224)):\n",
    "        model = nn.Sequential(*list(self.encoder.children())[:-1],\n",
    "                      nn.Flatten())\n",
    "        return model(torch.rand(*image_dim)).data.shape[1]\n",
    "\n",
    "    def _get_model(self):\n",
    "        resnet = self.encoder\n",
    "        model = nn.Sequential(*list(resnet.children())[:-1],\n",
    "                              nn.Flatten(),\n",
    "                              self.projection_head)\n",
    "        if self.checkpoint is not None:\n",
    "              # uncooment if the model was saved in data parallel!\n",
    "#             state_dict = torch.load(self.checkpoint)\n",
    "#             new_state_dict = OrderedDict()\n",
    "#             for k, v in state_dict.items():\n",
    "#                 name = k[7:] # remove `module.`\n",
    "#                 new_state_dict[name] = v\n",
    "#             model.load_state_dict(new_state_dict)\n",
    "            model.load_state_dict(torch.load(self.checkpoint))\n",
    "        return model\n",
    "\n",
    "    def _get_projection_head(self, in_size):\n",
    "        projection_head = nn.Sequential(nn.Linear(in_size, in_size),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(in_size, self.out_dim))\n",
    "        return projection_head\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e979d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification_model(torch.nn.Module):\n",
    "    def __init__(self, rep_model, input_dim, output_dim ):\n",
    "        super(classification_model, self).__init__()\n",
    "        self.rep_model = rep_model\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rep_model(x)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune = False\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d7674db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "set_seeds(0)\n",
    "encoder = SimCLREncoder('resnet18', 128, dev, DDP=False, checkpoint='aug_1/epoch_99')\n",
    "representation_model = representation_model(encoder.get_model())\n",
    "\n",
    "if not fine_tune:\n",
    "    representation_model.eval()\n",
    "    for param in representation_model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c76550",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "model_ft = classification_model(representation_model, 512, 2)\n",
    "model_ft.load_state_dict(torch.load('trial_2_multi_gpu_classifier/epoch_19'))\n",
    "model_ft = model_ft.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce00c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists!!\n",
      "epoch 20 of 25\n",
      "epoch loss: 8.554932199437697 epoch accuracy: 0.5391227506426736 validation accuracy: 0.790340909090909\n",
      "epoch 21 of 25\n",
      "epoch loss: 47.02837398303505 epoch accuracy: 0.5374558161953727 validation accuracy: 0.7869318181818182\n",
      "epoch 22 of 25\n",
      "epoch loss: 45.480270905482435 epoch accuracy: 0.5533218187660668 validation accuracy: 0.7863636363636364\n",
      "epoch 23 of 25\n",
      "epoch loss: 82.64133435717585 epoch accuracy: 0.5435812982005142 validation accuracy: 0.6431818181818182\n",
      "epoch 24 of 25\n",
      "epoch loss: 107.8288378163904 epoch accuracy: 0.5383394922879178 validation accuracy: 0.5856534090909091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(classification_model(\n",
       "   (rep_model): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "     (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "     (4): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (5): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (6): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (7): Sequential(\n",
       "       (0): BasicBlock(\n",
       "         (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (downsample): Sequential(\n",
       "           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (1): BasicBlock(\n",
       "         (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         (relu): ReLU(inplace=True)\n",
       "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "     (9): Flatten(start_dim=1, end_dim=-1)\n",
       "   )\n",
       "   (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       " ),\n",
       " [8.554932199437697,\n",
       "  47.02837398303505,\n",
       "  45.480270905482435,\n",
       "  82.64133435717585,\n",
       "  107.8288378163904],\n",
       " [0.5391227506426736,\n",
       "  0.5374558161953727,\n",
       "  0.5533218187660668,\n",
       "  0.5435812982005142,\n",
       "  0.5383394922879178],\n",
       " [0.5856534090909091])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seeds(0)\n",
    "optimiser = optim.SGD(model_ft.parameters(), lr=learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimiser, gamma=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.Tensor([0.19, 0.81])).to(dev)\n",
    "train(model_ft, train_loader, criterion, optimiser, num_epochs, dev, scheduler=None, start_point=20, val_data=val_loader, save_dir='trial_2_multi_gpu_classifier/')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
